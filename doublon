"""
GESTION DES DOUBLONS - SCRIPT OPTIMISÃ‰
=======================================

PROBLÃˆME :
    pd.merge() entre df_accepted0 et codeclient peut crÃ©er des doublons.
    Exemple :
        df_accepted0 : 1 ligne CLI001
        codeclient   : 3 lignes CLI001 (mÃªme client, mÃªme date, mÃªme montant)
        â†’ pd.merge() crÃ©e 3 lignes CLI001 dans le rÃ©sultat

    On veut :
        df_matched  : 1 ligne CLI001 (le premier match)
        df_doublons : 2 lignes CLI001 (les doublons)

STRATÃ‰GIE :
    1. Ajouter un ID unique Ã  chaque ligne de df_accepted0 AVANT le merge
    2. Faire le merge normalement
    3. NumÃ©roter les correspondances par ID (rang 1, 2, 3...)
    4. rang=1  â†’ matched  (une ligne sss = une ligne bbcc)
    5. rang>1  â†’ doublon  (une ligne sss = plusieurs lignes bbcc)
    6. ID absent du rÃ©sultat â†’ unmatched

"""

import pandas as pd


# ==============================================================================
# FONCTION PRINCIPALE : MERGE AVEC GESTION DES DOUBLONS
# ==============================================================================

def merge_avec_doublons(df_gauche, df_droite,
                        left_on, right_on,
                        suffixes=('_dfu', '_dfc')):
    """
    Effectue un merge pandas et sÃ©pare proprement :
        - df_matched  : chaque ligne gauche matchÃ©e une seule fois (rang 1)
        - df_doublons : lignes gauche matchÃ©es plusieurs fois (rang > 1)
        - df_unmatched_gauche : lignes gauche sans aucun match
        - df_unmatched_droite : lignes droite sans aucun match

    RÃˆGLE DOUBLON :
        Si une ligne de df_gauche correspond Ã  N lignes de df_droite :
          â†’ rang 1 = matched
          â†’ rang 2, 3, ..., N = doublons

    Args:
        df_gauche : DataFrame gauche  (ex: df_accepted0)
        df_droite : DataFrame droite  (ex: codeclient)
        left_on   : liste des colonnes de jointure cÃ´tÃ© gauche
        right_on  : liste des colonnes de jointure cÃ´tÃ© droite
        suffixes  : suffixes pour colonnes en doublon de nom

    Returns:
        dict avec les clÃ©s :
            'matched'           â†’ DataFrame (lignes 1:1)
            'doublons'          â†’ DataFrame (lignes 1:N, rang > 1)
            'unmatched_gauche'  â†’ DataFrame (pas de match dans droite)
            'unmatched_droite'  â†’ DataFrame (pas de match dans gauche)

    Exemple:
        >>> resultats = merge_avec_doublons(
        ...     df_accepted0, codeclient,
        ...     left_on  = ['CBS ID', 'DATE TRANSACTION', 'sens', 'MONTANT'],
        ...     right_on = ['CLI_S',  'DCO_S',            'SEN_S', 'MON_S'],
        ...     suffixes = ('_dfu', '_dfc')
        ... )
        >>> df_matched          = resultats['matched']
        >>> df_doublons         = resultats['doublons']
        >>> df_unmatched_sss     = resultats['unmatched_gauche']
        >>> df_unmatched_bbcc  = resultats['unmatched_droite']
    """

    # ------------------------------------------------------------------
    # Ã‰TAPE 1 : Ajouter un ID unique Ã  chaque ligne des deux cÃ´tÃ©s
    # ------------------------------------------------------------------
    # Pourquoi ?
    #   Sans ID, aprÃ¨s le merge, on ne peut pas savoir quelle ligne
    #   de df_gauche correspond Ã  quelle ligne de df_droite.
    #   L'ID nous permet de :
    #     - Compter combien de fois chaque ligne gauche apparaÃ®t (doublons)
    #     - Retrouver les lignes qui n'ont PAS matchÃ© (unmatched)

    df_g = df_gauche.copy()
    df_d = df_droite.copy()

    df_g['_id_g'] = range(len(df_g))  # 0, 1, 2, ... len(gauche)-1
    df_d['_id_d'] = range(len(df_d))  # 0, 1, 2, ... len(droite)-1

    # ------------------------------------------------------------------
    # Ã‰TAPE 2 : Merge INNER (uniquement les lignes qui matchent des 2 cÃ´tÃ©s)
    # ------------------------------------------------------------------
    df_merge = pd.merge(
        df_g,
        df_d,
        left_on=left_on,
        right_on=right_on,
        how='inner',
        suffixes=suffixes
    )

    # ------------------------------------------------------------------
    # Ã‰TAPE 3 : NumÃ©roter les correspondances PAR LIGNE GAUCHE ORIGINALE
    # ------------------------------------------------------------------
    # groupby('_id_g') groupe toutes les lignes du merge qui viennent
    # de la mÃªme ligne gauche originale.
    # cumcount() donne 0, 1, 2... â†’ +1 pour avoir 1, 2, 3...
    #
    # Exemple :
    #   CLI001 (id_g=0) apparaÃ®t 3 fois dans df_merge :
    #     â†’ rang 1 : CLI001 avec bbcc ligne A  â† matched
    #     â†’ rang 2 : CLI001 avec bbcc ligne B  â† doublon
    #     â†’ rang 3 : CLI001 avec bbcc ligne C  â† doublon

    if len(df_merge) > 0:
        df_merge['_rang'] = df_merge.groupby('_id_g').cumcount() + 1
    else:
        df_merge['_rang'] = []

    # ------------------------------------------------------------------
    # Ã‰TAPE 4 : SÃ©parer matched (rang=1) et doublons (rang>1)
    # ------------------------------------------------------------------
    df_matched  = df_merge[df_merge['_rang'] == 1].copy()
    df_doublons = df_merge[df_merge['_rang']  > 1].copy()

    # ------------------------------------------------------------------
    # Ã‰TAPE 5 : Trouver les unmatched (lignes sans aucun match)
    # ------------------------------------------------------------------
    # IDs des lignes gauche qui ont matchÃ© (au moins rang 1)
    ids_g_matched = set(df_matched['_id_g'])

    # IDs des lignes droite qui ont matchÃ©
    ids_d_matched = set(df_matched['_id_d']) | set(df_doublons['_id_d'])

    # Lignes gauche sans aucun match
    df_unmatched_gauche = df_gauche[~df_g['_id_g'].isin(ids_g_matched)].copy()

    # Lignes droite sans aucun match
    df_unmatched_droite = df_droite[~df_d['_id_d'].isin(ids_d_matched)].copy()

    # ------------------------------------------------------------------
    # Ã‰TAPE 6 : Nettoyer les colonnes temporaires
    # ------------------------------------------------------------------
    for col in ['_id_g', '_id_d', '_rang']:
        for df_ in [df_matched, df_doublons]:
            if col in df_.columns:
                df_.drop(columns=[col], inplace=True)

    return {
        'matched'          : df_matched,
        'doublons'         : df_doublons,
        'unmatched_gauche' : df_unmatched_gauche,
        'unmatched_droite' : df_unmatched_droite,
    }


# ==============================================================================
# TEST
# ==============================================================================

if __name__ == '__main__':

    print("=" * 60)
    print("TEST : GESTION DES DOUBLONS")
    print("=" * 60)

    # --------------------------------------------------------------------------
    # DonnÃ©es de test
    # --------------------------------------------------------------------------
    df_sss = pd.DataFrame({
        'CBS ID'          : ['CLI001', 'CLI002', 'CLI003', 'CLI004'],
        'DATE TRANSACTION': ['2026-02-10', '2026-02-10', '2026-02-11', '2026-02-10'],
        'sens'            : ['DEBIT',  'CREDIT', 'DEBIT',  'CREDIT'],
        'MONTANT'         : [100_000,   50_000,  75_000,  120_000],
    })

    df_bbcc = pd.DataFrame({
        'CLI_S' : ['CLI001', 'CLI001', 'CLI002', 'CLI003', 'CLI005'],
        #          â†‘ CLI001 en doublon !          â†‘ CLI005 n'existe pas dans sss
        'DCO_S' : ['2026-02-10', '2026-02-10', '2026-02-10', '2026-02-11', '2026-02-10'],
        'SEN_S' : ['DEBIT',      'DEBIT',       'CREDIT',     'DEBIT',      'CREDIT'],
        'MON_S' : [100_000,      100_000,        50_000,       75_000,       30_000],
    })

    print("\ndf_sss (gauche) :")
    print(df_sss.to_string(index=False))
    print(f"\ndf_bbcc (droite) :")
    print(df_bbcc.to_string(index=False))
    print(f"\nâ†’ CLI001 est en doublon dans df_bbcc (2 lignes identiques)")
    print(f"â†’ CLI004 n'est pas dans df_bbcc   (unmatched gauche)")
    print(f"â†’ CLI005 n'est pas dans df_sss       (unmatched droite)")

    # --------------------------------------------------------------------------
    # Appel de la fonction
    # --------------------------------------------------------------------------
    resultats = merge_avec_doublons(
        df_gauche = df_sss,
        df_droite = df_bbcc,
        left_on   = ['CBS ID', 'DATE TRANSACTION', 'sens', 'MONTANT'],
        right_on  = ['CLI_S',  'DCO_S',            'SEN_S', 'MON_S'],
        suffixes  = ('_dfu', '_dfc'),
    )

    df_matched         = resultats['matched']
    df_doublons        = resultats['doublons']
    df_unmatched_sss    = resultats['unmatched_gauche']
    df_unmatched_bbcc = resultats['unmatched_droite']

    # --------------------------------------------------------------------------
    # Affichage des rÃ©sultats
    # --------------------------------------------------------------------------
    print("\n" + "=" * 60)
    print("RÃ‰SULTATS")
    print("=" * 60)

    print(f"\nâœ… MATCHED ({len(df_matched)} ligne(s)) :")
    print("   Une ligne sss  â†”  une ligne bbcc")
    print(df_matched[['CBS ID', 'DATE TRANSACTION', 'MONTANT']].to_string(index=False))

    print(f"\nâš ï¸  DOUBLONS ({len(df_doublons)} ligne(s)) :")
    print("   Une ligne sss  â†”  plusieurs lignes bbcc (rang > 1)")
    if len(df_doublons) > 0:
        print(df_doublons[['CBS ID', 'DATE TRANSACTION', 'MONTANT']].to_string(index=False))
    else:
        print("   Aucun")

    print(f"\nâš ï¸  UNMATCHED sss ({len(df_unmatched_sss)} ligne(s)) :")
    print("   Dans sss mais pas dans bbcc")
    if len(df_unmatched_sss) > 0:
        print(df_unmatched_sss[['CBS ID', 'DATE TRANSACTION', 'MONTANT']].to_string(index=False))
    else:
        print("   Aucun")

    print(f"\nâš ï¸  UNMATCHED bbcc ({len(df_unmatched_bbcc)} ligne(s)) :")
    print("   Dans bbcc mais pas dans sss")
    if len(df_unmatched_bbcc) > 0:
        print(df_unmatched_bbcc[['CLI_S', 'DCO_S', 'MON_S']].to_string(index=False))
    else:
        print("   Aucun")

    # --------------------------------------------------------------------------
    # VÃ©rification des totaux
    # --------------------------------------------------------------------------
    print("\n" + "=" * 60)
    print("VÃ‰RIFICATION")
    print("=" * 60)
    print(f"  sss total     : {len(df_sss)}")
    print(f"  = matched    : {len(df_matched)}")
    print(f"  + unmatched  : {len(df_unmatched_sss)}")
    print(f"  = {len(df_matched) + len(df_unmatched_sss)} âœ…" if len(df_matched) + len(df_unmatched_sss) == len(df_sss) else "  â‰  ERREUR âŒ")

    print(f"\n  bbcc total  : {len(df_bbcc)}")
    print(f"  = matched    : {len(df_matched)}")
    print(f"  + doublons   : {len(df_doublons)}")
    print(f"  + unmatched  : {len(df_unmatched_bbcc)}")
    total_bbcc = len(df_matched) + len(df_doublons) + len(df_unmatched_bbcc)
    print(f"  = {total_bbcc} âœ…" if total_bbcc == len(df_bbcc) else f"  = {total_bbcc} â‰  ERREUR âŒ")

    print("\n" + "=" * 60)
    print("ðŸ’¡ UTILISATION DANS VOTRE CODE :")
    print("=" * 60)
    print("""
    from gestion_doublons import merge_avec_doublons

    resultats = merge_avec_doublons(
        df_gauche = df_accepted0,
        df_droite = codeclient,
        left_on   = ['CBS ID', 'DATE TRANSACTION', 'sens', 'MONTANT'],
        right_on  = ['CLI_S',  'DCO_S',            'SEN_S', 'MON_S'],
        suffixes  = ('_dfu', '_dfc'),
    )

    df_matched         = resultats['matched']
    df_doublons        = resultats['doublons']
    df_unmatched_sss    = resultats['unmatched_gauche']
    df_unmatched_bbcc = resultats['unmatched_droite']
    """)

_____________________________

"""
TRAITEMENT DES DOUBLONS ET MISE Ã€ JOUR DU FICHIER FINAL
========================================================

CONTEXTE :
    Les transactions "Ã  rÃ©gulariser" du jour J peuvent Ãªtre comptabilisÃ©es
    dans bk au jour J+1, J+2 ou J+3 (dÃ©calage temporel).
    
    Quand on dÃ©tecte un doublon bk (rang > 1), on vÃ©rifie si cette
    transaction Ã©tait "Ã  rÃ©gulariser" dans le fichier Final de la veille.
    Si oui â†’ on met Ã  jour l'indication en "comptabilisÃ©e" avec la date.

WORKFLOW :
    1. On a dÃ©tectÃ© les doublons avec merge_avec_doublons()
    2. On extrait les clÃ©s de jointure des doublons (rang > 1)
    3. On charge le fichier Final de la veille (historique)
    4. On cherche ces clÃ©s dans Final oÃ¹ indication='a regularise'
    5. On met Ã  jour : indication_nouvelle='comptabilisee', date_comptabilisation=DCO
    6. Si plusieurs correspondances â†’ on prend la plus ancienne (min date)
    7. On sauvegarde le Final mis Ã  jour

CLÃ‰S DE JOINTURE :
    - date
    - montant  
    - code (ou id client)
    - sens

Date: FÃ©vrier 2026
"""

import pandas as pd
from datetime import datetime, timedelta
import os


# ==============================================================================
# FONCTION 1 : EXTRAIRE LES CLÃ‰S DES DOUBLONS
# ==============================================================================

def extraire_cles_doublons(df_doublons, colonnes_cles):
    """
    Extrait les clÃ©s de jointure uniques des lignes en doublon.
    
    Args:
        df_doublons : DataFrame des doublons (rang > 1)
        colonnes_cles : liste des noms de colonnes formant la clÃ©
                       Ex: ['date', 'montant', 'code', 'sens']
    
    Returns:
        DataFrame avec uniquement les clÃ©s uniques des doublons
    
    Performance: O(n log n) avec drop_duplicates
    
    Exemple:
        >>> cles = extraire_cles_doublons(
        ...     df_doublons,
        ...     colonnes_cles=['date', 'montant', 'code', 'sens']
        ... )
        >>> print(cles)
        #        date  montant   code   sens
        # 0  10/02/26     5000  CLI01  DEBIT
        # 1  11/02/26    10000  CLI02  CREDIT
    """
    if len(df_doublons) == 0:
        print("   â„¹ï¸  Aucun doublon Ã  traiter")
        return pd.DataFrame(columns=colonnes_cles)
    
    # Extraire les colonnes clÃ©s et supprimer les doublons
    df_cles = df_doublons[colonnes_cles].drop_duplicates()
    
    print(f"   ðŸ“‹ {len(df_cles)} clÃ©(s) unique(s) extraite(s) des doublons")
    
    return df_cles


# ==============================================================================
# FONCTION 2 : CHARGER LE FICHIER FINAL DE LA VEILLE
# ==============================================================================

def charger_final_veille(chemin_final, plage_jours=3):
    """
    Charge le fichier Final cumulatif (historique des transactions).
    
    Le fichier Final contient l'historique des N derniers jours.
    On charge seulement les lignes rÃ©centes (plage_jours) pour optimiser.
    
    Args:
        chemin_final : chemin du fichier Final CSV
        plage_jours : nombre de jours d'historique Ã  garder (dÃ©faut: 3)
    
    Returns:
        DataFrame du fichier Final
    
    Colonnes attendues:
        date, montant, id, sens, code, statut_sss, statut_bbcc,
        indication, num_bk, indication_nouvelle,
        date_comptabilisation, date_execution
    
    Performance: O(n) pour la lecture, O(n) pour le filtrage date
    
    Exemple:
        >>> df_final = charger_final_veille('final_10_02_26.csv', plage_jours=3)
        >>> print(f"ChargÃ©: {len(df_final)} lignes")
    """
    if not os.path.exists(chemin_final):
        print(f"   âš ï¸  Fichier Final non trouvÃ© : {chemin_final}")
        print(f"   â†’ CrÃ©ation d'un DataFrame vide")
        return pd.DataFrame()
    
    # Charger le fichier
    df_final = pd.read_csv(chemin_final, dtype={'code': str, 'id': str})
    
    print(f"   ðŸ“‚ Fichier Final chargÃ© : {len(df_final):,} lignes")
    
    # Convertir la date en datetime pour filtrer
    df_final['date'] = pd.to_datetime(df_final['date'], format='%d/%m/%Y', errors='coerce')
    
    # Filtrer les N derniers jours (optimisation mÃ©moire)
    if len(df_final) > 0 and plage_jours > 0:
        date_limite = df_final['date'].max() - pd.Timedelta(days=plage_jours)
        df_final = df_final[df_final['date'] >= date_limite]
        print(f"   ðŸ” AprÃ¨s filtrage (derniers {plage_jours} jours) : {len(df_final):,} lignes")
    
    return df_final


# ==============================================================================
# FONCTION 3 : METTRE Ã€ JOUR LE FINAL AVEC LES DOUBLONS COMPTABILISÃ‰S
# ==============================================================================

def mettre_a_jour_final_avec_doublons(df_doublons, df_final_veille, 
                                       colonnes_cles, date_execution):
    """
    Met Ã  jour le fichier Final en marquant les doublons comme "comptabilisÃ©s".
    
    LOGIQUE :
        1. Extraire les clÃ©s des doublons (rang > 1)
        2. Chercher ces clÃ©s dans Final oÃ¹ indication='a regularise'
        3. Si trouvÃ© â†’ mettre Ã  jour :
           - indication_nouvelle = 'comptabilisee'
           - date_comptabilisation = date du doublon (DCO)
        4. Si plusieurs lignes Final matchent â†’ garder la plus ancienne
        5. Marquer ces lignes avec date_execution (traÃ§abilitÃ©)
    
    Args:
        df_doublons : DataFrame des doublons dÃ©tectÃ©s
        df_final_veille : DataFrame du fichier Final chargÃ©
        colonnes_cles : liste des colonnes de jointure
        date_execution : date du traitement du jour (format datetime ou str)
    
    Returns:
        df_final_mis_a_jour : DataFrame Final avec les mises Ã  jour
    
    Performance: O(n log m) avec jointure pandas optimisÃ©e
    
    Exemple:
        >>> df_final_maj = mettre_a_jour_final_avec_doublons(
        ...     df_doublons,
        ...     df_final_veille,
        ...     colonnes_cles=['date', 'montant', 'code', 'sens'],
        ...     date_execution='18/02/2026'
        ... )
    """
    print("\n" + "="*70)
    print("MISE Ã€ JOUR DU FICHIER FINAL AVEC LES DOUBLONS")
    print("="*70)
    
    # Convertir date_execution en string format DD/MM/YYYY si datetime
    if isinstance(date_execution, (datetime, pd.Timestamp)):
        date_execution_str = date_execution.strftime('%d/%m/%Y')
    else:
        date_execution_str = date_execution
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 1 : Extraire les clÃ©s des doublons
    # -------------------------------------------------------------------------
    print("\n1ï¸âƒ£ Extraction des clÃ©s des doublons...")
    df_cles_doublons = extraire_cles_doublons(df_doublons, colonnes_cles)
    
    if len(df_cles_doublons) == 0:
        print("   âœ… Aucun doublon Ã  traiter, Final inchangÃ©")
        return df_final_veille
    
    # Ajouter la date de comptabilisation (= date du doublon)
    # On suppose que df_doublons a une colonne 'DCO_S' ou 'date' pour la date bbcc
    if 'DCO_S' in df_doublons.columns:
        colonne_date_bbcc = 'DCO_S'
    elif 'date' in df_doublons.columns:
        colonne_date_bbcc = 'date'
    else:
        colonne_date_bbcc = colonnes_cles[0]  # Par dÃ©faut, premiÃ¨re clÃ© (souvent 'date')
    
    # CrÃ©er un mapping clÃ© â†’ date de comptabilisation
    df_cles_avec_date = df_doublons[colonnes_cles + [colonne_date_bbcc]].copy()
    df_cles_avec_date = df_cles_avec_date.drop_duplicates(subset=colonnes_cles)
    df_cles_avec_date.rename(columns={colonne_date_bbcc: '_date_comptabilisation_doublon'}, inplace=True)
    
    # Convertir les colonnes date en datetime pour harmoniser avec Final
    for col in colonnes_cles:
        if 'date' in col.lower():
            df_cles_avec_date[col] = pd.to_datetime(df_cles_avec_date[col], format='%d/%m/%Y', errors='coerce')
        elif 'montant' in col.lower():
            df_cles_avec_date[col] = pd.to_numeric(df_cles_avec_date[col], errors='coerce')
        elif col in ['code', 'id', 'sens']:
            df_cles_avec_date[col] = df_cles_avec_date[col].astype(str)
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 2 : Filtrer le Final sur indication='a regularise'
    # -------------------------------------------------------------------------
    print("\n2ï¸âƒ£ Recherche dans le Final (indication='a regularise')...")
    
    if len(df_final_veille) == 0:
        print("   âš ï¸  Fichier Final vide, aucune mise Ã  jour possible")
        return df_final_veille
    
    # Filtrer seulement les lignes "Ã  rÃ©gulariser"
    df_final_a_regulariser = df_final_veille[
        df_final_veille['indication'].str.lower().str.strip() == 'a regularise'
    ].copy()
    
    print(f"   â†’ {len(df_final_a_regulariser):,} lignes 'Ã  rÃ©gulariser' dans Final")
    
    if len(df_final_a_regulariser) == 0:
        print("   âœ… Aucune ligne 'Ã  rÃ©gulariser', Final inchangÃ©")
        return df_final_veille
    
    # Harmoniser les types des colonnes clÃ©s dans Final
    for col in colonnes_cles:
        if col in df_final_a_regulariser.columns:
            if 'montant' in col.lower():
                df_final_a_regulariser[col] = pd.to_numeric(df_final_a_regulariser[col], errors='coerce')
            elif col in ['code', 'id', 'sens']:
                df_final_a_regulariser[col] = df_final_a_regulariser[col].astype(str)
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 3 : Jointure pour trouver les correspondances
    # -------------------------------------------------------------------------
    print("\n3ï¸âƒ£ Jointure Final â†” ClÃ©s doublons...")
    
    # Ajouter un ID unique au Final pour tracer les lignes
    df_final_a_regulariser['_id_final'] = range(len(df_final_a_regulariser))
    
    # Jointure sur les clÃ©s
    df_correspondances = pd.merge(
        df_final_a_regulariser,
        df_cles_avec_date,
        on=colonnes_cles,
        how='inner'
    )
    
    print(f"   â†’ {len(df_correspondances):,} correspondance(s) trouvÃ©e(s)")
    
    if len(df_correspondances) == 0:
        print("   âœ… Aucune correspondance, Final inchangÃ©")
        return df_final_veille
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 4 : Si plusieurs correspondances â†’ garder la plus ancienne
    # -------------------------------------------------------------------------
    print("\n4ï¸âƒ£ Gestion des multiples correspondances (garder la plus ancienne)...")
    
    # Compter les doublons de correspondance
    nb_multiples = df_correspondances.groupby(colonnes_cles).size()
    nb_avec_multiples = (nb_multiples > 1).sum()
    
    if nb_avec_multiples > 0:
        print(f"   âš ï¸  {nb_avec_multiples} clÃ©(s) avec plusieurs correspondances dans Final")
        print(f"   â†’ On garde la ligne la plus ancienne (min date) pour chaque clÃ©")
        
        # Grouper par clÃ©s et garder l'ID de la ligne avec la date la plus ancienne
        idx_a_garder = df_correspondances.groupby(colonnes_cles)['date'].idxmin()
        df_correspondances = df_correspondances.loc[idx_a_garder]
        
        print(f"   â†’ AprÃ¨s dÃ©duplication : {len(df_correspondances):,} ligne(s)")
    else:
        print(f"   âœ… Aucune correspondance multiple, pas de dÃ©duplication nÃ©cessaire")
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 5 : Mettre Ã  jour les colonnes
    # -------------------------------------------------------------------------
    print("\n5ï¸âƒ£ Mise Ã  jour des colonnes...")
    
    # IDs des lignes Final Ã  mettre Ã  jour
    ids_a_maj = set(df_correspondances['_id_final'])
    
    # CrÃ©er un mapping _id_final â†’ date_comptabilisation
    mapping_date_compta = df_correspondances.set_index('_id_final')['_date_comptabilisation_doublon'].to_dict()
    
    # Copier le Final pour modification
    df_final_maj = df_final_veille.copy()
    
    # S'assurer que les colonnes texte sont bien de type object (string)
    for col in ['indication_nouvelle', 'date_comptabilisation', 'date_execution']:
        if col in df_final_maj.columns:
            df_final_maj[col] = df_final_maj[col].astype(object)
    
    # Ajouter un ID temporaire pour faciliter la mise Ã  jour
    df_final_maj['_id_temp'] = range(len(df_final_maj))
    
    # Identifier les lignes Ã  mettre Ã  jour
    mask_a_maj = df_final_maj['_id_temp'].isin(
        df_final_a_regulariser[df_final_a_regulariser['_id_final'].isin(ids_a_maj)].index
    )
    
    nb_maj = mask_a_maj.sum()
    print(f"   â†’ {nb_maj} ligne(s) Ã  mettre Ã  jour dans Final")
    
    # Mettre Ã  jour indication_nouvelle
    df_final_maj.loc[mask_a_maj, 'indication_nouvelle'] = 'comptabilisee'
    
    # Mettre Ã  jour date_comptabilisation
    # Il faut mapper avec l'ID final
    for idx_final in df_final_a_regulariser[df_final_a_regulariser['_id_final'].isin(ids_a_maj)].index:
        if idx_final in mapping_date_compta:
            date_compta = mapping_date_compta.get(
                df_final_a_regulariser.loc[idx_final, '_id_final']
            )
            if pd.notna(date_compta):
                df_final_maj.loc[idx_final, 'date_comptabilisation'] = pd.to_datetime(date_compta).strftime('%d/%m/%Y')
    
    # Mettre Ã  jour date_execution (traÃ§abilitÃ© du traitement)
    df_final_maj.loc[mask_a_maj, 'date_execution'] = date_execution_str
    
    # Nettoyer les colonnes temporaires
    df_final_maj.drop(columns=['_id_temp'], inplace=True)
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 6 : RÃ©sumÃ©
    # -------------------------------------------------------------------------
    print("\n" + "="*70)
    print("ðŸ“Š RÃ‰SUMÃ‰ DES MISES Ã€ JOUR")
    print("="*70)
    print(f"âœ… {nb_maj} ligne(s) mise(s) Ã  jour :")
    print(f"   â€¢ indication_nouvelle = 'comptabilisee'")
    print(f"   â€¢ date_comptabilisation = date du doublon")
    print(f"   â€¢ date_execution = {date_execution_str}")
    print("="*70)
    
    return df_final_maj


# ==============================================================================
# FONCTION 4 : SAUVEGARDER LE FINAL MIS Ã€ JOUR
# ==============================================================================

def sauvegarder_final(df_final, chemin_sortie):
    """
    Sauvegarde le fichier Final mis Ã  jour.
    
    Args:
        df_final : DataFrame Final mis Ã  jour
        chemin_sortie : chemin de sauvegarde du fichier CSV
    
    Returns:
        None
    
    Exemple:
        >>> sauvegarder_final(df_final_maj, 'final_11_02_26.csv')
    """
    # Convertir les dates en format DD/MM/YYYY pour le CSV
    for col in ['date', 'date_comptabilisation', 'date_execution']:
        if col in df_final.columns:
            df_final[col] = pd.to_datetime(df_final[col], errors='coerce').dt.strftime('%d/%m/%Y')
    
    df_final.to_csv(chemin_sortie, index=False)
    print(f"\nðŸ’¾ Fichier Final sauvegardÃ© : {chemin_sortie}")
    print(f"   â†’ {len(df_final):,} lignes")


# ==============================================================================
# FONCTION PRINCIPALE : ORCHESTRATION COMPLÃˆTE
# ==============================================================================

def traiter_regularisation_doublons(df_doublons, 
                                     chemin_final_veille,
                                     chemin_final_sortie,
                                     colonnes_cles=['date', 'montant', 'code', 'sens'],
                                     date_execution=None):
    """
    Orchestre le traitement complet des doublons et la mise Ã  jour du Final.
    
    WORKFLOW COMPLET :
        1. Charger le fichier Final de la veille
        2. Extraire les clÃ©s des doublons (rang > 1)
        3. Chercher ces clÃ©s dans Final oÃ¹ indication='a regularise'
        4. Mettre Ã  jour : indication_nouvelle='comptabilisee', date_comptabilisation
        5. Sauvegarder le Final mis Ã  jour
    
    Args:
        df_doublons : DataFrame des doublons dÃ©tectÃ©s (rang > 1)
        chemin_final_veille : chemin du fichier Final de la veille
        chemin_final_sortie : chemin de sauvegarde du Final mis Ã  jour
        colonnes_cles : liste des colonnes de jointure
        date_execution : date du traitement (dÃ©faut: aujourd'hui)
    
    Returns:
        df_final_maj : DataFrame Final mis Ã  jour
    
    Exemple d'utilisation:
        >>> from gestion_doublons import merge_avec_doublons
        >>> from regularisation_doublons import traiter_regularisation_doublons
        >>> 
        >>> # Ã‰tape 1 : DÃ©tecter les doublons
        >>> resultats = merge_avec_doublons(df_accepted0, codeclient, ...)
        >>> df_doublons = resultats['doublons']
        >>> 
        >>> # Ã‰tape 2 : Traiter les doublons et mettre Ã  jour Final
        >>> df_final_maj = traiter_regularisation_doublons(
        ...     df_doublons,
        ...     chemin_final_veille='final_10_02_26.csv',
        ...     chemin_final_sortie='final_11_02_26.csv',
        ...     colonnes_cles=['date', 'montant', 'code', 'sens'],
        ...     date_execution='11/02/2026'
        ... )
    """
    print("\n" + "="*70)
    print("TRAITEMENT DES RÃ‰GULARISATIONS - DOUBLONS")
    print("="*70)
    
    # Date par dÃ©faut = aujourd'hui
    if date_execution is None:
        date_execution = datetime.now().strftime('%d/%m/%Y')
    
    print(f"ðŸ“… Date d'exÃ©cution : {date_execution}")
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 1 : Charger le Final de la veille
    # -------------------------------------------------------------------------
    print(f"\nðŸ“‚ Chargement du fichier Final de la veille...")
    df_final_veille = charger_final_veille(chemin_final_veille, plage_jours=3)
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 2 : Mettre Ã  jour avec les doublons
    # -------------------------------------------------------------------------
    df_final_maj = mettre_a_jour_final_avec_doublons(
        c,
        df_final_veille,
        colonnes_cles,
        date_execution
    )
    
    # -------------------------------------------------------------------------
    # Ã‰TAPE 3 : Sauvegarder
    # -------------------------------------------------------------------------
    sauvegarder_final(df_final_maj, chemin_final_sortie)
    
    return df_final_maj


# ==============================================================================
# TEST COMPLET
# ==============================================================================

if __name__ == '__main__':
    
    print("\n" + "="*70)
    print("ðŸ§ª TEST COMPLET : RÃ‰GULARISATION DES DOUBLONS")
    print("="*70)
    
    # -------------------------------------------------------------------------
    # CrÃ©er un fichier Final de test (simule la veille)
    # -------------------------------------------------------------------------
    df_final_test = pd.DataFrame({
        'date'                  : ['10/02/2026', '11/02/2026', '11/02/2026'],
        'montant'               : [5000,         5000,         10000],
        'id'                    : ['TXN001',     'TXN001',     'TXN002'],
        'sens'                  : ['D',          'D',          'C'],
        'code'                  : ['CLI01',      'CLI01',      'CLI02'],
        'statut_sss'             : ['OK',         'OK',         'OK'],
        'statut_bbcc'          : ['OK',         'OK',         'OK'],
        'indication'            : ['comptabilisÃ©e', 'a regularise', 'a regularise'],
        'num_bk'             : ['BK001',      'BK005',      'BK006'],
        'indication_nouvelle'   : ['',           '',           ''],
        'date_comptabilisation' : ['',           '',           ''],
        'date_execution'        : ['10/02/2026', '',           ''],
    })
    
    # Sauvegarder le Final de test
    df_final_test.to_csv('final_10_02_26_test.csv', index=False)
    print("\nðŸ“„ Fichier Final de test crÃ©Ã© : final_10_02_26_test.csv")
    print(df_final_test.to_string(index=False))
    
    # -------------------------------------------------------------------------
    # CrÃ©er des doublons de test
    # -------------------------------------------------------------------------
    df_doublons_test = pd.DataFrame({
        'date'   : ['11/02/2026', '11/02/2026'],
        'montant': [5000,         10000],
        'code'   : ['CLI01',      'CLI02'],
        'sens'   : ['D',          'C'],
        'DCO_S'  : ['11/02/2026', '11/02/2026'],
        '_rang'  : [2,            2],  # rang > 1 = doublon
    })
    
    print("\nðŸ“„ Doublons dÃ©tectÃ©s (rang > 1) :")
    print(df_doublons_test.to_string(index=False))
    
    # -------------------------------------------------------------------------
    # Traiter la rÃ©gularisation
    # -------------------------------------------------------------------------
    df_final_maj = traiter_regularisation_doublons(
        df_doublons         = df_doublons_test,
        chemin_final_veille = 'final_10_02_26_test.csv',
        chemin_final_sortie = 'final_11_02_26_test.csv',
        colonnes_cles       = ['date', 'montant', 'code', 'sens'],
        date_execution      = '11/02/2026'
    )
    
    # -------------------------------------------------------------------------
    # Afficher le rÃ©sultat
    # -------------------------------------------------------------------------
    print("\n" + "="*70)
    print("ðŸ“‹ FICHIER FINAL MIS Ã€ JOUR")
    print("="*70)
    print(df_final_maj[['date', 'code', 'montant', 'indication', 
                        'indication_nouvelle', 'date_comptabilisation', 
                        'date_execution']].to_string(index=False))
    
    print("\n" + "="*70)
    print("âœ… TEST TERMINÃ‰")
    print("="*70)
    
    print("""
ðŸ’¡ UTILISATION EN PRODUCTION :

    from gestion_doublons import merge_avec_doublons
    from regularisation_doublons import traiter_regularisation_doublons
    
    # Ã‰tape 1 : DÃ©tecter les doublons
    resultats = merge_avec_doublons(
        df_accepted0, codeclient,
        left_on=['CBS ID', 'DATE TRANSACTION', 'sens', 'MONTANT'],
        right_on=['CLI_S', 'DCO_S', 'SEN_S', 'MON_S']
    )
    
    df_doublons = resultats['doublons']
    
    # Ã‰tape 2 : Mettre Ã  jour le Final avec les rÃ©gularisations
    df_final_maj = traiter_regularisation_doublons(
        df_doublons,
        chemin_final_veille='final_10_02_26.csv',
        chemin_final_sortie='final_11_02_26.csv',
        colonnes_cles=['date', 'montant', 'code', 'sens'],
        date_execution='11/02/2026'
    )
    """)
